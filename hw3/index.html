<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<!-- Updated CSS styles for a modern, professional look -->
<style>
:root {
  --bg: #eaf2fb;
  --surface: #ffffff;
  --text: #1e293b;
  --muted: #556070;
  --primary: #1a73e8;
  --border: #e2e8f0;
  --shadow: 0 6px 20px rgba(0, 0, 0, 0.07);
}

* { box-sizing: border-box; }

body {
  background: var(--bg);
  padding: 40px 20px;
  margin: 0;
  font-family: 'Open Sans', sans-serif;
  color: var(--text);
  line-height: 1.7;
}

.container {
  max-width: 1200px;
  margin: 0 auto;
}

.site-header {
  background: var(--surface);
  border: 1px solid var(--border);
  border-radius: 12px;
  box-shadow: var(--shadow);
  padding: 16px 20px;
  margin-bottom: 24px;
}

.site-header .brand { text-align: center; }

.topnav {
  display: flex;
  justify-content: center;
  gap: 18px;
  flex-wrap: wrap;
  margin-top: 10px;
}

.topnav a {
  color: var(--primary);
  text-decoration: none;
  font-weight: 600;
  padding: 8px 10px;
  border-radius: 8px;
}

.topnav a:hover {
  background: #eef3fe;
  text-decoration: none;
}

h1, h2, h3, h4 {
  color: #111827;
  font-family: 'Source Sans Pro', sans-serif;
  margin: 0 0 12px;
}

h1 { text-align: center; margin-bottom: 24px; }

a { color: var(--primary); text-decoration: none; }
a:hover { text-decoration: underline; }

.card {
  background: var(--surface);
  border: 1px solid var(--border);
  border-radius: 16px;
  box-shadow: var(--shadow);
  padding: 24px 28px;
  margin-bottom: 28px;
}

table {
  width: 100%;
  border-collapse: collapse;
  margin: 16px 0;
  background: var(--surface);
  overflow: hidden;
  border-radius: 12px;
}

th, td {
  padding: 12px;
  text-align: center;
  border-bottom: 1px solid var(--border);
}

th {
  background: #f6f9ff;
  color: #0f172a;
  font-weight: 700;
}

tr:last-child td { border-bottom: none; }

img {
  border-radius: 10px;
  box-shadow: 0 4px 16px rgba(0, 0, 0, 0.08);
}

pre {
  background: #0f172a;
  color: #e5e7eb;
  border-radius: 10px;
  padding: 16px;
  overflow-x: auto;
  box-shadow: var(--shadow);
}

code {
  font-family: 'Fira Mono', 'Courier New', Courier, monospace;
  background: #e8edf7;
  color: #0f172a;
  border-radius: 6px;
  padding: 2px 6px;
}

section { margin-bottom: 0; }
</style>
<!-- End Updated CSS Styles -->

<title>CS 184 Advanced Path Tracer: A Journey in Rendering</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>
<div class="container">
  <header class="site-header">
    <div class="brand">
      <h2>Samyak Tiwari, Sufjan Fana</h2>
      <p><a href="https://cal-cs184.github.io/samyak-sufjan/hw3/">https://cal-cs184.github.io/samyak-sufjan/hw3/</a></p>
    </div>
    <nav class="topnav">
      <a href="#overview">Overview</a>
      <a href="#part1">Part 1</a>
      <a href="#part2">Part 2</a>
      <a href="#part3">Part 3</a>
      <a href="#part4">Part 4</a>
      <a href="#part5">Part 5</a>
    </nav>
  </header>

  <h1>CS 184 Advanced Path Tracer: A Journey in Rendering</h1>


  <section id="overview" class="card">
    <h2>Overview</h2>
    <p>
      This project implements a physically-based path tracer from scratch, capable of rendering photorealistic images by simulating the complex interactions of light with surfaces. The assignment required building a full rendering pipeline, including ray generation, intersection tests, acceleration structures, direct and indirect lighting, and adaptive sampling. I learned how Monte Carlo integration underpins realistic rendering, how acceleration structures like BVH make complex scenes tractable, and how sampling strategies affect both image quality and performance. The most interesting aspect was seeing how small changes in sampling or recursion depth could dramatically change the realism of the output. This project deepened my appreciation for the trade-offs between efficiency and visual fidelity in computer graphics.
    </p>
  </section>


  <section id="part1" class="card">
    <h2>Part 1</h2>
    <h3>Ray Generation and Primitive Intersection</h3>
    <p>
      The rendering pipeline begins with ray generation. For each pixel, <code>Camera::generate_ray</code> computes the direction by mapping normalized sensor coordinates to the camera's sensor plane, then transforms this direction into world space using the camera-to-world matrix. The ray is spawned from the camera position and clipped to the near and far planes. This process is tightly integrated with primitive intersection: rays are tested against all scene primitives, and only those within the valid range are considered.
    </p>
  <h3>Triangle Intersection (Möller–Trumbore Algorithm)</h3>
  <p>
    For triangles, I implemented the Möller–Trumbore algorithm. This method computes two edge vectors from the triangle's vertices, then uses the cross and dot products to determine if the ray and triangle are parallel. If not, it solves for barycentric coordinates (u, v) and the intersection distance t. The intersection is valid if u, v are in [0,1], their sum is ≤ 1, and t is within the ray's range. This approach is efficient and numerically stable, making it ideal for real-time and offline rendering.
  </p>
  <h3>Sphere Intersection</h3>
  <p>
    Sphere intersection is handled by solving the quadratic equation for the intersection of a ray and a sphere. The closest valid root within the ray's range is chosen as the intersection point.
  </p>

  <h3>Rendered Images (Normal Shading, Small .dae Files)</h3>
  <p>Below are the rendered images with normal shading for a few small .dae files, demonstrating correct implementation of ray generation and intersection:</p>
  <div align="center">
    <table style="width:100%">
      <tr align="center">
        <td>
          <img src="./images/P1/dragon.png" width="300px" alt="dragon.dae"/>
          <figcaption>dragon.dae</figcaption>
        </td>
        <td>
          <img src="./images/P1/gems.png" width="300px" alt="CBgems.dae"/>
          <figcaption>CBgems.dae</figcaption>
        </td>
        <td>
          <img src="./images/P1/spheres.png" width="300px" alt="CBspheres.dae"/>
          <figcaption>CBspheres.dae</figcaption>
        </td>
      </tr>
    </table>
  </div>
  <!-- End of Part 1 section -->
  </section>

  <section id="part2" class="card">
    <h2>Part 2</h2>
    <div>
      <h3>BVH Construction Algorithm</h3>
    <p>
      To accelerate intersection tests, I implemented a Bounding Volume Hierarchy (BVH). The BVH is built recursively: for a set of primitives, I compute their bounding box and choose the splitting axis as the one with the largest spread in centroid positions. The split point is the midpoint along this axis, which helps balance the tree. Each node is then subdivided until a leaf node contains a small number of primitives. This reduces the number of intersection tests from O(n) to O(log n) per ray, making rendering of complex scenes feasible.
    </p>
<pre><code class="language-cpp">
// Example BVH node splitting function
void buildBVH(Node* node, const std::vector&lt;Primitive&gt; &primitives) {
    // Compute bounding box for primitives
    // Determine the splitting axis based on centroid spread
    // Split primitives and recursively build child nodes
    // ...
}
</code></pre>

  <h3>Images Rendered with BVH Acceleration (Large .dae Files)</h3>
  <p>The following images show normal shading for a few large .dae files that can only be rendered efficiently using BVH acceleration. These scenes would be prohibitively slow to render without BVH:</p>
    <div align="center">
      <table style="width:100%" border="1" cellspacing="0" cellpadding="5">
        <tr align="center">
          <th>Scene</th>
          <th>Image</th>
          <th>Primitives</th>
        </tr>
        <tr align="center">
          <td>Lucy</td>
          <td><img src="./images/P2/lucy_133796.png" width="200px" alt="lucy_133796.dae"/></td>
          <td>133,796</td>
        </tr>
        <tr align="center">
          <td>Wall-e</td>
          <td><img src="./images/P2/wall-e_240326.png" width="200px" alt="wall-e_240326.dae"/></td>
          <td>240,326</td>
        </tr>
        <tr align="center">
          <td>Dragon</td>
          <td><img src="./images/P2/dragon_105120.png" width="200px" alt="dragon_105120.dae"/></td>
          <td>105,120</td>
        </tr>
      </table>
    </div>

  <h3>Rendering Time Comparison and Analysis</h3>
  <p>The table below compares rendering times for scenes with moderately complex geometries, both with and without BVH acceleration. The images on the left display the scene rendered with BVH acceleration, along with the number of thousands of rays drawn and the BVH rendering time. The right column shows estimated render times without BVH. <b>Analysis:</b> At roughly 150–226k rays, BVH prunes intersection tests to a logarithmic number per ray, yielding speedups of about 500–1200× in our examples (Beetle: ~1215×, Cow: ~1248×, Teapot: ~523×). This turns renders from tens of seconds without BVH (full O(n) primitive sweeps per ray) to tens or hundreds of milliseconds with BVH, enabling interactive iteration. As scene complexity grows, the gap widens because BVH traversal scales with tree depth while brute force grows linearly with primitives; cache-friendlier bounding checks also reduce wasted computation. In short, BVH is essential for practical rendering beyond toy scenes.</p>
    <div align="center">
      <table style="width:100%" border="1" cellspacing="0" cellpadding="5">
        <tr align="center">
          <th>Scene</th>
          <th>Thousands of Rays</th>
          <th>Render Time with BVH</th>
          <th>Render Time without BVH</th>
          <th>Image</th>
        </tr>
        <tr align="center">
          <td>Beetle</td>
          <td>153</td>
          <td>0.0266 s</td>
          <td>32.3 s</td>
          <td><img src="./images/P2/beetle_153_00266.png" width="200px" alt="beetle_153_00266.png"/></td>
        </tr>
        <tr align="center">
          <td>Cow</td>
          <td>189</td>
          <td>0.033 s</td>
          <td>41.2 s</td>
          <td><img src="./images/P2/cow_189_0033.png" width="200px" alt="cow_189_0033.png"/></td>
        </tr>
        <tr align="center">
          <td>Teapot</td>
          <td>226</td>
          <td>0.1276 s</td>
          <td>66.7 s</td>
          <td><img src="./images/P2/teapot_226_01276.png" width="200px" alt="teapot_226_01276.png"/></td>
        </tr>
      </table>
    </div>

    <p>This analysis clearly indicates that BVH acceleration drastically reduces rendering times, even for scenes that require drawing hundreds of thousands of rays. Without BVH, the render times are orders of magnitude higher, as illustrated by our estimates.</p>
  </div>
  <!-- End of updated Part 2 section -->
  </section>

  <section id="part3" class="card">
    <h2>Part 3</h2>
    <!-- Begin Direct Lighting Comparison Section -->
  <h3>Direct Lighting Implementations: Walkthrough and Comparison</h3>
  <p>
    I implemented two approaches for direct lighting: uniform hemisphere sampling and importance (lighting) sampling. In uniform hemisphere sampling, directions are sampled uniformly over the hemisphere at the hit point, and the contribution from each sample is weighted by the BSDF and cosine term. In importance sampling, directions are sampled according to the light source's distribution, focusing computation on directions that contribute most to the final image. This reduces noise and variance, especially for area lights. Below are images rendered with both methods for several scenes.
  </p>
  <div align="center">
    <table style="width:100%" border="1" cellspacing="0" cellpadding="5">
      <tr align="center">
        <th>Scene</th>
        <th>Uniform Hemisphere Sampling</th>
        <th>Importance Lighting Sampling</th>
      </tr>
      <tr align="center">
        <td>Bunny</td>
        <td><img src="./images/P3/hBunny.png" width="200px" alt="hBunny.png"/></td>
        <td><img src="./images/P3/iBunny.png" width="200px" alt="iBunny.png"/></td>
      </tr>
      <tr align="center">
        <td>Lucy</td>
        <td><img src="./images/P3/hLucy.png" width="200px" alt="hLucy.png"/></td>
        <td><img src="./images/P3/iLucy.png" width="200px" alt="iLucy.png"/></td>
      </tr>
      <tr align="center">
        <td>Spheres</td>
        <td><img src="./images/P3/hSpheres.png" width="200px" alt="hSpheres.png"/></td>
        <td><img src="./images/P3/iSpheres.png" width="200px" alt="iSpheres.png"/></td>
      </tr>
    </table>
  </div>

  <h3>Soft Shadows Noise Comparison (Spheres Scene, Area Light)</h3>
  <p>The following images show the spheres scene rendered with 1, 4, 16, and 64 light rays (using the -l flag) and 1 sample per pixel (-s flag), using light sampling. As the number of light rays increases, noise in soft shadows is significantly reduced, resulting in smoother and more realistic shading.</p>
  <div align="center">
    <table style="width:100%" border="1" cellspacing="0" cellpadding="5">
      <tr align="center">
        <th>Light Rays</th>
        <th>Image</th>
      </tr>
      <tr align="center">
        <td>1</td>
        <td><img src="./images/P3/spheres1.png" width="200px" alt="spheres1.png"/></td>
      </tr>
      <tr align="center">
        <td>4</td>
        <td><img src="./images/P3/spheres4.png" width="200px" alt="spheres4.png"/></td>
      </tr>
      <tr align="center">
        <td>16</td>
        <td><img src="./images/P3/spheres16.png" width="200px" alt="spheres16.png"/></td>
      </tr>
      <tr align="center">
        <td>64</td>
        <td><img src="./images/P3/spheres64.png" width="200px" alt="spheres64.png"/></td>
      </tr>
    </table>
  </div>
  <p><em>Parameters:</em> -l in {1, 4, 16, 64}, -s 1, lighting sampling enabled; all other settings identical.</p>

  <p><b>Analysis:</b> Uniform hemisphere sampling provides a baseline estimation of direct lighting, but importance sampling significantly reduces noise in soft shadows, especially for area lights. This results in smoother and more accurate renders under identical sampling conditions, making importance sampling the preferred method for scenes with complex lighting.</p>
  <!-- End Direct Lighting Comparison Section -->

  <!-- Insert walkthrough explanation for direct lighting implementations in Part 3 -->
  <h3>Direct Lighting: Implementation Details</h3>
  <p>In the <strong>uniform hemisphere sampling</strong> approach, a local coordinate system is formed at the hit point, and directions are sampled uniformly over the hemisphere. For each sample, a shadow ray is cast; if it hits a light, the contribution is computed by multiplying the BSDF, incoming radiance, and cosine term, then scaled by 2π. The Monte Carlo estimator is:</p>

  <blockquote>
    \[
    \frac{1}{N} \sum_{j=1}^{N} \frac{ f_r(\mathbf{p}, \omega_j \rightarrow \omega_r)\, L_i(\mathbf{p}, \omega_j)\, \cos\theta_j }{ p(\omega_j) }
    \]
  </blockquote>

  <p>Since the sampling is uniform, <code>p(ω)</code> is constant. In <strong>importance sampling</strong>, the sampling strategy is tailored to the light sources. For each light, especially area lights, a sample is generated in the direction of the light, and the probability density <code>p(ω)</code> reflects the likelihood of sampling that direction. A shadow ray is cast to ensure the light is not blocked. This method reduces noise and variance by focusing samples on significant lighting contributions.</p>

  <!-- Begin Direct Lighting Code Snippets Insertion -->
  <h4>Code Snippet: Uniform Hemisphere Sampling</h4>
  <pre><code class="language-cpp">
// Uniform hemisphere sampling
Vector3 sampleDir = uniformSampleHemisphere(hit.normal);
// cast shadow ray and accumulate if not occluded
return (2 * M_PI * result) / numSamples;
</code></pre>

  <h4>Code Snippet: Importance Sampling</h4>
  <pre><code class="language-cpp">
// Importance sampling toward lights
Vector3 sampleDir = importanceSampleLight(hit.position, &pdf);
// cast shadow ray and accumulate light contribution / pdf
return result / numSamples;
</code></pre>
  <!-- End Direct Lighting Code Snippets Insertion -->

  <!-- Begin Diffuse BSDF Sampling Section -->
  <h3>Diffuse BSDF Sampling</h3>
  <p>For diffuse materials, <code>DiffuseBSDF::sample_f</code> samples an incoming light direction using a cosine-weighted distribution and returns the Lambertian BSDF value. This ensures that diffuse materials reflect light equally in all directions, following the Lambertian reflectance model.</p>
<pre><code class="language-cpp">
// Diffuse BSDF sampling snippet
Vector3 sample = sampler.get_sample();
*pdf = (sample.z > 0) ? sample.z / M_PI : 0;
return reflectance / M_PI;
</code></pre>
<p>This implementation follows the Lambertian reflectance model, ensuring that diffuse materials reflect light equally in all directions.</p>
  <!-- End Diffuse BSDF Sampling Section -->
  <h3>Uniform Hemisphere vs Lighting Sampling: Analysis</h3>
  <p>Lighting sampling concentrates samples toward actual light directions, drastically lowering variance, especially with area lights and small bright sources. At equal SPP (with the same -l value), it yields smoother soft shadows and cleaner contact regions, whereas uniform hemisphere sampling expends many samples on low-contribution directions and thus converges slowly with visible speckle. Both estimators are unbiased, but lighting sampling achieves much faster convergence per sample. Uniform hemisphere sampling is scene-agnostic and simple to implement, yet requires far higher sample counts to match the quality of lighting sampling. In our spheres scene, lighting sampling delivers the softest, least noisy penumbrae under identical sampling budgets.</p>
  </section>

  <section id="part4" class="card">
    <h2>Part 4</h2>

    <!-- Begin Global Illumination Renderings Section -->
  <h3>Indirect Lighting: Walkthrough and Global Illumination Renderings</h3>
  <p>
    Indirect lighting is implemented by recursively spawning new rays at each intersection, simulating multiple bounces of light. The <code>at_least_one_bounce_radiance</code> function accumulates radiance from both direct and indirect paths. Russian Roulette termination is used to probabilistically end low-contribution paths, maintaining unbiased results while improving efficiency. Below are images rendered with both direct and indirect illumination (global illumination) using 1024 samples per pixel.
  </p>
<div align="center">
  <table style="width:100%" border="1" cellspacing="0" cellpadding="5">
    <tr align="center">
       <th>Scene</th>
       <th>Image</th>
    </tr>
    <tr align="center">
       <td>Bunny</td>
       <td><img src="./images/P4/bunnyGlobalM2.png" width="300px" alt="bunnyGlobalM2.png"/></td>
    </tr>
    <tr align="center">
       <td>Coil</td>
       <td><img src="./images/P4/coilGlobalM2.png" width="300px" alt="coilGlobalM2.png"/></td>
    </tr>
    <tr align="center">
       <td>Spheres</td>
       <td><img src="./images/P4/spheresGlobalM2.png" width="300px" alt="spheresGlobalM2.png"/></td>
    </tr>
  </table>
</div>
<!-- End Global Illumination Renderings Section -->

  <!-- Begin Direct vs Indirect Illumination Comparison Section -->
<h3>Direct vs Indirect Illumination Comparison for CBspheres_lambertian.dae</h3>
<p>For the scene rendered from <strong>CBspheres_lambertian.dae</strong> with 1024 samples per pixel, I generated two views: one with only direct illumination and another with only indirect illumination. The direct lighting image captures the contribution from light sources, while the indirect lighting image highlights the effect of light bouncing off surfaces. Indirect illumination adds brightness and realism, filling in shadows and producing subtle color bleeding.</p>
<div align="center">
  <table style="width:100%" border="1" cellspacing="0" cellpadding="5">
    <tr align="center">
      <th>Direct Illumination</th>
      <th>Indirect Illumination</th>
    </tr>
    <tr align="center">
      <td><img src="./images/P4/spheresDirect.png" width="300px" alt="spheresDirect.png"/></td>
      <td><img src="./images/P4/spheresIndirect.png" width="300px" alt="spheresIndirect.png"/></td>
    </tr>
  </table>
</div>
<!-- End Direct vs Indirect Illumination Comparison Section -->

  <!-- Begin CBbunny Bounce Comparison Section -->
<h3>CBbunny Bounce Comparison</h3>
<p>For <strong>CBbunny.dae</strong> (1024 samples per pixel), I rendered images with max ray depth m ∈ {0, 1, 2, 3, 4, 5} for both accumulated and unaccumulated bounces. For the unaccumulated set, I explicitly used <code>isAccumBounces = false</code> to visualize the pure m-th bounce contribution. Observations: the <strong>2nd bounce</strong> adds noticeable fill light and subtle color bleeding onto adjacent surfaces, reducing harsh contrast; the <strong>3rd bounce</strong> strengthens interreflections and further evens illumination. Compared to rasterization (which lacks indirect light), these bounces materially improve realism and soft shading. Accumulated bounces show the combined effect up to depth m, while unaccumulated images isolate each bounce.</p>
<div align="center">
  <table style="width:100%;" border="1" cellspacing="0" cellpadding="5">
    <tr align="center">
      <th>Ray Depth (m)</th>
      <th>Unaccumulated (o0)</th>
      <th>Accumulated (o1)</th>
    </tr>
    <tr align="center">
      <td>0</td>
      <td><img src="./images/P4/T2m0o0.png" width="300px" alt="T2m0o0.png"/></td>
      <td><img src="./images/P4/T2m0o1.png" width="300px" alt="T2m0o1.png"/></td>
    </tr>
    <tr align="center">
      <td>1</td>
      <td><img src="./images/P4/T2m1o0.png" width="300px" alt="T2m1o0.png"/></td>
      <td><img src="./images/P4/T2m1o1.png" width="300px" alt="T2m1o1.png"/></td>
    </tr>
    <tr align="center">
      <td>2</td>
      <td><img src="./images/P4/T2m2o0.png" width="300px" alt="T2m2o0.png"/></td>
      <td><img src="./images/P4/T2m2o1.png" width="300px" alt="T2m2o1.png"/></td>
    </tr>
    <tr align="center">
      <td>3</td>
      <td><img src="./images/P4/T2m3o0.png" width="300px" alt="T2m3o0.png"/></td>
      <td><img src="./images/P4/T2m3o1.png" width="300px" alt="T2m3o1.png"/></td>
    </tr>
    <tr align="center">
      <td>4</td>
      <td><img src="./images/P4/T2m4o0.png" width="300px" alt="T2m4o0.png"/></td>
      <td><img src="./images/P4/T2m4o1.png" width="300px" alt="T2m4o1.png"/></td>
    </tr>
    <tr align="center">
      <td>5</td>
      <td><img src="./images/P4/T2m5o0.png" width="300px" alt="T2m5o0.png"/></td>
      <td><img src="./images/P4/T2m5o1.png" width="300px" alt="T2m5o1.png"/></td>
    </tr>
  </table>
</div>
<p><em>Accumulated vs unaccumulated:</em> The accumulated images brighten and denoise progressively with m, while the unaccumulated views reveal diminishing per-bounce energy after the 3rd bounce, explaining why moderate max depths suffice in practice.</p>
<!-- End CBbunny Bounce Comparison Section -->

  <!-- Begin Russian Roulette Rendering Section for CBbunny.dae -->
<h3>Russian Roulette Rendering for CBbunny.dae</h3>
<p>Russian Roulette termination is used to reduce computation while maintaining unbiased results. For <strong>CBbunny.dae</strong>, I rendered images with max ray depth set to 0, 1, 2, 3, 4, and 100, using 1024 samples per pixel. Russian Roulette probabilistically terminates low-contribution paths, and the estimator is:</p>
<blockquote>
\[
X_{rr} = \begin{cases}
\dfrac{X}{p_{rr}}, & \text{with probability } p_{rr}, \\
0, & \text{otherwise}.
\end{cases}
\]
</blockquote>
<p><strong>Same expected value as original estimator:</strong></p>
<blockquote>
\[
E[X_{rr}] = p_{rr} \; E\left[ \frac{X}{p_{rr}} \right] + (1 - p_{rr}) \; E[0] = E[X]
\]
</blockquote>
<p>This technique ensures that even though some paths are terminated early, the final estimate remains unbiased, as the contribution from surviving paths is appropriately scaled.</p>
<p>The following table shows the Russian Roulette renderings for CBbunny.dae with max_ray_depth set to 0, 1, 2, 3, 4, and 100 (using 1024 samples per pixel):</p>
<div align="center">
  <table style="width:100%;" border="1" cellspacing="0" cellpadding="5">
    <tr align="center">
      <th>Max Ray Depth (m)</th>
      <th>Image</th>
    </tr>
    <tr align="center">
      <td>0</td>
      <td><img src="./images/P4/T3m0.png" width="300px" alt="T3m0.png"/></td>
    </tr>
    <tr align="center">
      <td>1</td>
      <td><img src="./images/P4/T3m1.png" width="300px" alt="T3m1.png"/></td>
    </tr>
    <tr align="center">
      <td>2</td>
      <td><img src="./images/P4/T3m2.png" width="300px" alt="T3m2.png"/></td>
    </tr>
    <tr align="center">
      <td>3</td>
      <td><img src="./images/P4/T3m3.png" width="300px" alt="T3m3.png"/></td>
    </tr>
    <tr align="center">
      <td>4</td>
      <td><img src="./images/P4/T3m4.png" width="300px" alt="T3m4.png"/></td>
    </tr>
    <tr align="center">
      <td>100</td>
      <td><img src="./images/P4/T3m100.png" width="300px" alt="T3m100.png"/></td>
    </tr>
  </table>
</div>
<p><b>Observation at m=100:</b> When m = 100, many white pixels appeared scattered throughout the image. This indicated that error was accumulating in <code>L_out</code>. For paths where Russian Roulette did not terminate the light ray after many bounces, their contributions were over-amplified, lighting those pixels too much.</p>
<!-- End Russian Roulette Rendering Section -->

  <!-- Begin Sample-per-Pixel Rate Comparison Section for CBspheres_lambertian.dae -->
<h3>Sample-per-Pixel Rate Comparison for CBspheres_lambertian.dae</h3>
<p>To illustrate the effect of sample-per-pixel (SPP) rates, I rendered <strong>CBspheres_lambertian.dae</strong> with 1, 2, 4, 8, 16, 64, and 1024 SPP, using 4 light rays and Russian Roulette. As SPP increases, noise decreases and the image becomes smoother. The file paths for the images are shown below each sample rate.</p>
<div align="center">
  <table style="width:100%" border="1" cellspacing="0" cellpadding="5">
    <tr align="center">
      <th>Samples per Pixel</th>
      <th>Image</th>
    </tr>
    <tr align="center">
      <td>1</td>
      <td><img src="./images/P4/1.png" width="300px" alt="./images/P4/1.png"/><br/><code>./images/P4/1.png</code></td>
    </tr>
    <tr align="center">
      <td>2</td>
      <td><img src="./images/P4/2.png" width="300px" alt="./images/P4/2.png"/><br/><code>./images/P4/2.png</code></td>
    </tr>
    <tr align="center">
      <td>4</td>
      <td><img src="./images/P4/4.png" width="300px" alt="./images/P4/4.png"/><br/><code>./images/P4/4.png</code></td>
    </tr>
    <tr align="center">
      <td>8</td>
      <td><img src="./images/P4/8.png" width="300px" alt="./images/P4/8.png"/><br/><code>./images/P4/8.png</code></td>
    </tr>
    <tr align="center">
      <td>16</td>
      <td><img src="./images/P4/16.png" width="300px" alt="./images/P4/16.png"/><br/><code>./images/P4/16.png</code></td>
    </tr>
    <tr align="center">
      <td>64</td>
      <td><img src="./images/P4/64.png" width="300px" alt="./images/P4/64.png"/><br/><code>./images/P4/64.png</code></td>
    </tr>
    <tr align="center">
      <td>1024</td>
      <td><img src="./images/P4/1024.png" width="300px" alt="./images/P4/1024.png"/><br/><code>./images/P4/1024.png</code></td>
    </tr>
  </table>
</div>
  <!-- End Sample-per-Pixel Rate Comparison Section -->
  </section>

  <section id="part5" class="card">
    <h2>Part 5</h2>
    <h3>Adaptive Sampling: Explanation and Implementation</h3>
  <p>
    Adaptive sampling is used to concentrate computational effort on pixels with high variance, reducing noise where needed and saving samples in well-converged regions. In <code>PathTracer::raytrace_pixel</code>, each pixel is initially sampled with a single ray, and then iteratively resampled until convergence is detected. After each new sample, the running mean (μ) and variance (σ²) of the pixel’s radiance values are updated. The variance is computed as:
  </p>
  <blockquote>
    \[
    \sigma^2 = \frac{1}{n}\sum_{k=1}^{n} x_k^2 - \mu^2
    \]
  </blockquote>
  <p>
    The 95% confidence interval is:
  </p>
  <blockquote>
    \[
    I = 1.96 \times \frac{\sigma}{\sqrt{n}}
    \]
  </blockquote>
  <p>
    Sampling stops when the confidence interval satisfies:
  </p>
  <blockquote>
    \[
    I \leq \text{maxTolerance} \times \mu
    \]
  </blockquote>
  <p>
    This technique ensures that more samples are allocated to noisy regions, resulting in efficient and high-quality renders.
  </p>

  <!-- Begin Adaptive Sampling Renderings Section -->
<h3>Adaptive Sampling Renderings</h3>
<p>
  Below are adaptive sampling renderings for the bunny and sphere scenes from <code>CBbunny.dae</code>, using at least 2048 samples per pixel, 1 sample per light, and a max ray depth of 5. For each scene, the sample rate image (with <code>_rate</code> in the filename) shows how adaptive sampling varies across different regions, while the other image is the noise-free rendered result.
</p>
<div align="center">
  <table style="width:100%" border="1" cellspacing="0" cellpadding="5">
    <tr align="center">
      <th>Scene</th>
      <th>Sample Rate Image</th>
      <th>Noise-Free Rendered Image</th>
    </tr>
    <tr align="center">
      <td>Bunny</td>
      <td><img src="./images/P5/bunny_rate.png" width="300px" alt="Adaptive Sampling Rate for Bunny"/></td>
      <td><img src="./images/P5/bunny.png" width="300px" alt="Noise-Free Rendered Bunny"/></td>
    </tr>
    <tr align="center">
      <td>Sphere</td>
      <td><img src="./images/P5/sphere_rate.png" width="300px" alt="Adaptive Sampling Rate for Sphere"/></td>
      <td><img src="./images/P5/sphere.png" width="300px" alt="Noise-Free Rendered Sphere"/></td>
    </tr>
  </table>
</div>
<!-- End Adaptive Sampling Renderings Section -->
  </section>
</div>
</body>
</html>
